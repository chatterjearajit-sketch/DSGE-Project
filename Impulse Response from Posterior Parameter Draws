import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import solve_discrete_lyapunov
from scipy.stats import norm
import pandas as pd
from typing import Tuple, Dict, List

class DSGEModel:
    """
    A class to handle the DSGE model with IS curve, Phillips curve, and Taylor rule
    """
    
    def __init__(self, params: Dict[str, float]):
        """
        Initialize the DSGE model with parameters
        
        Parameters:
        -----------
        params : dict
            Dictionary containing model parameters:
            - sigma: inverse of elasticity of intertemporal substitution
            - beta: discount factor
            - kappa: slope of Phillips curve
            - phi_pi: Taylor rule coefficient on inflation
            - phi_x: Taylor rule coefficient on output gap
            - rho_a: persistence of technology shock
            - rho_u: persistence of cost-push shock
        """
        self.params = params
        self.state_names = ['x_hat', 'pi', 'i', 'a_hat', 'u']
        self.shock_names = ['eps_a', 'eps_u']
        
    def solve_model(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        Solve the DSGE model using the method of undetermined coefficients
        Returns the solution matrices for the state-space representation:
        X_t = A * X_{t-1} + B * eps_t
        
        Returns:
        --------
        A : np.ndarray
            Transition matrix
        B : np.ndarray
            Impact matrix for shocks
        """
        # Extract parameters
        sigma = self.params['sigma']
        beta = self.params['beta']
        kappa = self.params['kappa']
        phi_pi = self.params['phi_pi']
        phi_x = self.params['phi_x']
        rho_a = self.params['rho_a']
        rho_u = self.params['rho_u']
        
        # State vector: [x_hat_t, pi_t, i_t, a_hat_t, u_t]
        # The model in matrix form: Gamma0 * X_t = Gamma1 * X_{t-1} + Psi * eps_t + Pi * eta_t
        # where eta_t are expectation errors
        
        # For this simple model, we can solve analytically
        # From Taylor rule: i_t = phi_pi * pi_t + phi_x * x_hat_t
        # Substituting into IS curve and using rational expectations
        
        # Coefficients for the solved system
        denom = 1 + kappa * phi_x / sigma + kappa * phi_pi / sigma
        
        # Transition matrix A
        A = np.zeros((5, 5))
        
        # Output gap equation coefficients
        A[0, 0] = (1 + kappa * phi_x / sigma) / denom  # x_hat on x_hat_{t-1}
        A[0, 1] = kappa * phi_pi / (sigma * denom)      # x_hat on pi_{t-1}
        A[0, 3] = rho_a / (sigma * denom)               # x_hat on a_hat_{t-1}
        A[0, 4] = -1 / (sigma * denom)                  # x_hat on u_{t-1}
        
        # Inflation equation coefficients
        A[1, 0] = kappa * (1 + kappa * phi_x / sigma) / denom  # pi on x_hat_{t-1}
        A[1, 1] = kappa**2 * phi_pi / (sigma * denom)          # pi on pi_{t-1}
        A[1, 3] = kappa * rho_a / (sigma * denom)              # pi on a_hat_{t-1}
        A[1, 4] = (1 - kappa / (sigma * denom))                # pi on u_{t-1}
        
        # Interest rate (from Taylor rule)
        A[2, 0] = phi_x * A[0, 0] + phi_pi * A[1, 0]   # i on x_hat_{t-1}
        A[2, 1] = phi_x * A[0, 1] + phi_pi * A[1, 1]   # i on pi_{t-1}
        A[2, 3] = phi_x * A[0, 3] + phi_pi * A[1, 3]   # i on a_hat_{t-1}
        A[2, 4] = phi_x * A[0, 4] + phi_pi * A[1, 4]   # i on u_{t-1}
        
        # Technology shock AR(1)
        A[3, 3] = rho_a
        
        # Cost-push shock AR(1)
        A[4, 4] = rho_u
        
        # Impact matrix B for shocks [eps_a, eps_u]
        B = np.zeros((5, 2))
        
        # Technology shock impacts
        B[0, 0] = rho_a / (sigma * denom)       # eps_a on x_hat
        B[1, 0] = kappa * rho_a / (sigma * denom)  # eps_a on pi
        B[2, 0] = phi_x * B[0, 0] + phi_pi * B[1, 0]  # eps_a on i
        B[3, 0] = 1                             # eps_a on a_hat
        
        # Cost-push shock impacts
        B[0, 1] = -1 / (sigma * denom)          # eps_u on x_hat
        B[1, 1] = 1 - kappa / (sigma * denom)   # eps_u on pi
        B[2, 1] = phi_x * B[0, 1] + phi_pi * B[1, 1]  # eps_u on i
        B[4, 1] = 1                             # eps_u on u
        
        return A, B
    
    def compute_impulse_response(self, A: np.ndarray, B: np.ndarray, 
                               shock_idx: int, periods: int = 20) -> np.ndarray:
        """
        Compute impulse response function for a given shock
        
        Parameters:
        -----------
        A : np.ndarray
            Transition matrix
        B : np.ndarray
            Impact matrix
        shock_idx : int
            Index of the shock (0 for technology, 1 for cost-push)
        periods : int
            Number of periods for the impulse response
            
        Returns:
        --------
        irf : np.ndarray
            Impulse response matrix (variables x periods)
        """
        n_vars = A.shape[0]
        irf = np.zeros((n_vars, periods))
        
        # Initial impact
        irf[:, 0] = B[:, shock_idx]
        
        # Subsequent periods
        for t in range(1, periods):
            irf[:, t] = A @ irf[:, t-1]
            
        return irf

def generate_posterior_draws(n_draws: int = 1000) -> List[Dict[str, float]]:
    """
    Generate posterior parameter draws (simulated for demonstration)
    In practice, these would come from MCMC estimation
    """
    np.random.seed(42)  # For reproducibility
    
    posterior_draws = []
    
    for _ in range(n_draws):
        # Simulated posterior draws with realistic priors
        params = {
            'sigma': max(0.1, np.random.normal(2.0, 0.5)),      # Inv. elast. of substitution
            'beta': np.random.beta(50, 2) * 0.02 + 0.98,       # Discount factor
            'kappa': max(0.01, np.random.normal(0.1, 0.03)),   # Phillips curve slope
            'phi_pi': max(1.01, np.random.normal(1.5, 0.3)),   # Taylor rule inflation
            'phi_x': max(0.01, np.random.normal(0.5, 0.2)),    # Taylor rule output
            'rho_a': np.random.beta(8, 2) * 0.4 + 0.6,         # Technology persistence
            'rho_u': np.random.beta(5, 5) * 0.8 + 0.1,         # Cost-push persistence
        }
        posterior_draws.append(params)
    
    return posterior_draws

def plot_impulse_responses(posterior_draws: List[Dict[str, float]], 
                         periods: int = 20, 
                         confidence_bands: List[float] = [0.68, 0.95]):
    """
    Plot impulse responses with uncertainty bands from posterior draws
    """
    n_draws = len(posterior_draws)
    n_vars = 5
    n_shocks = 2
    
    # Store all impulse responses
    all_irfs = np.zeros((n_draws, n_vars, periods, n_shocks))
    
    # Compute IRFs for each posterior draw
    for i, params in enumerate(posterior_draws):
        model = DSGEModel(params)
        A, B = model.solve_model()
        
        # Technology shock
        all_irfs[i, :, :, 0] = model.compute_impulse_response(A, B, 0, periods)
        
        # Cost-push shock
        all_irfs[i, :, :, 1] = model.compute_impulse_response(A, B, 1, periods)
    
    # Variable names for plotting
    var_names = ['Output Gap', 'Inflation', 'Interest Rate', 'Technology', 'Cost-Push']
    shock_names = ['Technology Shock', 'Cost-Push Shock']
    
    # Create plots
    fig, axes = plt.subplots(2, 5, figsize=(20, 10))
    fig.suptitle('Impulse Response Functions with Posterior Uncertainty', fontsize=16)
    
    colors = ['blue', 'red']
    
    for shock_idx in range(n_shocks):
        for var_idx in range(n_vars):
            ax = axes[shock_idx, var_idx]
            
            # Get IRF data for this variable and shock
            irf_data = all_irfs[:, var_idx, :, shock_idx]
            
            # Compute percentiles
            median_irf = np.percentile(irf_data, 50, axis=0)
            
            # Plot confidence bands
            for conf_level in confidence_bands:
                alpha = 1 - conf_level
                lower = np.percentile(irf_data, 100 * alpha/2, axis=0)
                upper = np.percentile(irf_data, 100 * (1 - alpha/2), axis=0)
                
                band_alpha = 0.3 if conf_level == 0.68 else 0.2
                ax.fill_between(range(periods), lower, upper, 
                               alpha=band_alpha, color=colors[shock_idx],
                               label=f'{int(conf_level*100)}% CI')
            
            # Plot median
            ax.plot(range(periods), median_irf, 
                   color=colors[shock_idx], linewidth=2, label='Median')
            
            # Add zero line
            ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)
            
            # Formatting
            ax.set_title(f'{var_names[var_idx]}')
            ax.set_xlabel('Periods')
            ax.grid(True, alpha=0.3)
            
            # Add legend only to first subplot of each row
            if var_idx == 0:
                ax.legend()
                ax.set_ylabel(f'{shock_names[shock_idx]}')
    
    plt.tight_layout()
    plt.show()
    
    return all_irfs

def summary_statistics(all_irfs: np.ndarray, periods: int = 20):
    """
    Compute and display summary statistics for impulse responses
    """
    var_names = ['Output Gap', 'Inflation', 'Interest Rate', 'Technology', 'Cost-Push']
    shock_names = ['Technology Shock', 'Cost-Push Shock']
    
    print("Summary Statistics for Impulse Responses")
    print("=" * 50)
    
    for shock_idx in range(2):
        print(f"\n{shock_names[shock_idx]}:")
        print("-" * 30)
        
        for var_idx in range(5):
            # Peak response
            peak_responses = np.max(np.abs(all_irfs[:, var_idx, :, shock_idx]), axis=1)
            peak_mean = np.mean(peak_responses)
            peak_std = np.std(peak_responses)
            
            # Impact response (period 0)
            impact_responses = all_irfs[:, var_idx, 0, shock_idx]
            impact_mean = np.mean(impact_responses)
            impact_std = np.std(impact_responses)
            
            # Long-run response (period 19)
            longrun_responses = all_irfs[:, var_idx, periods-1, shock_idx]
            longrun_mean = np.mean(longrun_responses)
            longrun_std = np.std(longrun_responses)
            
            print(f"{var_names[var_idx]}:")
            print(f"  Impact: {impact_mean:.4f} ({impact_std:.4f})")
            print(f"  Peak:   {peak_mean:.4f} ({peak_std:.4f})")
            print(f"  Long-run: {longrun_mean:.4f} ({longrun_std:.4f})")

# Example usage
if __name__ == "__main__":
    # Generate posterior draws
    print("Generating posterior parameter draws...")
    posterior_draws = generate_posterior_draws(n_draws=1000)
    
    # Plot impulse responses
    print("Computing and plotting impulse responses...")
    all_irfs = plot_impulse_responses(posterior_draws, periods=20)
    
    # Display summary statistics
    summary_statistics(all_irfs)
    
    # Example: Access specific IRF data
    print("\nExample: Technology shock impact on output gap")
    tech_shock_output = all_irfs[:, 0, :, 0]  # [draws, output_gap, periods, tech_shock]
    print(f"Median impact: {np.median(tech_shock_output[:, 0]):.4f}")
    print(f"68% CI: [{np.percentile(tech_shock_output[:, 0], 16):.4f}, {np.percentile(tech_shock_output[:, 0], 84):.4f}]")
